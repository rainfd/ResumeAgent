"""ç«¯åˆ°ç«¯å·¥ä½œæµé›†æˆæµ‹è¯• - ä½¿ç”¨çœŸå®æ•°æ®"""

import unittest
import asyncio
import tempfile
import sys
import json
import os
from pathlib import Path
from datetime import datetime
from unittest.mock import patch, MagicMock, AsyncMock

# æ·»åŠ srcè·¯å¾„åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent.parent / "src"))

from resume_assistant.data.database import DatabaseManager
from resume_assistant.core.job_manager import Job, JobManager
from resume_assistant.data.models import JobInfo, ResumeContent
from resume_assistant.core.ai_analyzer import AIAnalyzer, AnalysisResult
from resume_assistant.core.scraper import ScrapingResult
from resume_assistant.core.resume_processor import ResumeProcessor
from resume_assistant.utils.errors import (
    DatabaseError, AIAnalysisError, ResumeProcessingError, NetworkError
)


# åŠ è½½çœŸå®æ•°æ®
def load_real_jobs_data():
    """åŠ è½½çœŸå®èŒä½æ•°æ®"""
    project_root = Path(__file__).parent.parent.parent
    jobs_data = []
    
    # åŠ è½½æ‰€æœ‰èŒä½æ•°æ®
    job_files = [
        "5c384a14-4174-4c51-b5b9-87ef63454441.json",  # Pythonåç«¯
        "2b62bee0-3659-47a0-b175-efa18e0eaa44.json",  # AIç®—æ³•å·¥ç¨‹å¸ˆ
        "594e9122-8f0e-499f-87c9-0f92d1d4e2d8.json"   # å…¨æ ˆå·¥ç¨‹å¸ˆ
    ]
    
    for job_file in job_files:
        job_path = project_root / "data" / "jobs" / job_file
        if job_path.exists():
            with open(job_path, 'r', encoding='utf-8') as f:
                jobs_data.append(json.load(f))
    
    return jobs_data

def load_real_resumes_data():
    """åŠ è½½çœŸå®ç®€å†æ•°æ®"""
    project_root = Path(__file__).parent.parent.parent
    resumes_data = []
    
    # åŠ è½½ç®€å†æ–‡ä»¶
    resume_files = [
        ("test_resume_1.md", "å¼ ä¸‰", "å‰ç«¯å¼€å‘"),
        ("test_resume_2.md", "æå››", "åç«¯å¼€å‘")
    ]
    
    for resume_file, name, role in resume_files:
        resume_path = project_root / "data" / "resumes" / resume_file
        if resume_path.exists():
            with open(resume_path, 'r', encoding='utf-8') as f:
                content = f.read()
                resumes_data.append({
                    "filename": resume_file,
                    "content": content,
                    "name": name,
                    "role": role,
                    "path": str(resume_path)
                })
    
    return resumes_data

def load_real_metadata():
    """åŠ è½½çœŸå®å…ƒæ•°æ®"""
    project_root = Path(__file__).parent.parent.parent
    
    # åŠ è½½ç®€å†å…ƒæ•°æ®
    resume_metadata_file = project_root / "data" / "resumes" / "resumes_metadata.json"
    resume_metadata = {}
    if resume_metadata_file.exists():
        with open(resume_metadata_file, 'r', encoding='utf-8') as f:
            resume_metadata = json.load(f)
    
    # åŠ è½½èŒä½å…ƒæ•°æ®
    job_metadata_file = project_root / "data" / "jobs" / "jobs_metadata.json"
    job_metadata = {}
    if job_metadata_file.exists():
        with open(job_metadata_file, 'r', encoding='utf-8') as f:
            job_metadata = json.load(f)
    
    return resume_metadata, job_metadata


class TestEndToEndWorkflow(unittest.TestCase):
    """ç«¯åˆ°ç«¯å·¥ä½œæµæµ‹è¯• - ä½¿ç”¨çœŸå®æ•°æ®"""
    
    def setUp(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        # åˆ›å»ºä¸´æ—¶æ•°æ®åº“
        self.temp_db = tempfile.NamedTemporaryFile(delete=False, suffix='.db')
        self.temp_db.close()
        
        self.db_manager = DatabaseManager(self.temp_db.name)
        self.job_manager = JobManager(self.db_manager)
        self.resume_processor = ResumeProcessor()
        self.ai_analyzer = AIAnalyzer()
        
        # åŠ è½½çœŸå®æ•°æ®
        self.real_jobs = load_real_jobs_data()
        self.real_resumes = load_real_resumes_data()
        self.resume_metadata, self.job_metadata = load_real_metadata()
    
    def tearDown(self):
        """æ¸…ç†æµ‹è¯•ç¯å¢ƒ"""
        asyncio.run(self.db_manager.close())
        try:
            os.unlink(self.temp_db.name)
        except OSError:
            pass
    
    async def test_complete_job_analysis_workflow_with_real_data(self):
        """æµ‹è¯•ä½¿ç”¨çœŸå®æ•°æ®çš„å®Œæ•´èŒä½åˆ†æå·¥ä½œæµ"""
        if not self.real_jobs or not self.real_resumes:
            self.skipTest("çœŸå®æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨")
        
        await self.db_manager.initialize()
        
        # 1. ä½¿ç”¨çœŸå®èŒä½æ•°æ®è¿›è¡Œçˆ¬å–æ¨¡æ‹Ÿ
        real_job = self.real_jobs[0]  # Pythonåç«¯å¼€å‘å·¥ç¨‹å¸ˆ
        
        with patch.object(self.job_manager, 'scrape_job') as mock_scrape:
            job = Job(
                id=real_job['id'],
                title=real_job['title'],
                company=real_job['company'],
                location=real_job['location'],
                source_url=f"https://www.lagou.com/jobs/{real_job['id']}.html",
                salary=real_job['salary'],
                requirements=real_job['requirements'],
                description=real_job['description']
            )
            mock_scrape.return_value = ScrapingResult(
                success=True,
                job=job,
                url=f"https://www.lagou.com/jobs/{real_job['id']}.html",
                scraped_at=datetime.now()
            )
            
            # çˆ¬å–å¹¶ä¿å­˜èŒä½
            job_result = await self.job_manager.scrape_job(f"https://www.lagou.com/jobs/{real_job['id']}.html")
            job_id = await self.job_manager.save_job(job_result)
            
            self.assertIsNotNone(job_id)
            self.assertEqual(job_result.job.title, "Pythonåç«¯å¼€å‘å·¥ç¨‹å¸ˆ")
            self.assertEqual(job_result.job.company, "ç§‘æŠ€æœ‰é™å…¬å¸A")
        
        # 2. ä½¿ç”¨çœŸå®ç®€å†æ•°æ®
        real_resume = self.real_resumes[1]  # æå››çš„åç«¯ç®€å†
        
        # å¤„ç†çœŸå®ç®€å†æ–‡ä»¶
        resume_data = self.resume_processor.process_file(real_resume["path"])
        resume_id = await self.db_manager.save_resume(Resume(
            id=resume_data["id"],
            filename=real_resume["filename"],
            file_path=real_resume["path"],
            content=real_resume["content"],
            parsed_data=resume_data.get("parsed_data", {})
        ))
        
        self.assertIsNotNone(resume_id)
        
        # 3. ä½¿ç”¨çœŸå®æ•°æ®è¿›è¡ŒAIåˆ†æ
        with patch.object(self.ai_analyzer, 'analyze_resume') as mock_analyze:
            # åŸºäºçœŸå®æ•°æ®ç‰¹å¾ç”Ÿæˆåˆ†æç»“æœ
            realistic_analysis = f"""## æå››ç®€å†ä¸{real_job['title']}èŒä½åŒ¹é…åˆ†æ

### æŠ€èƒ½åŒ¹é…åº¦è¯„ä¼°ï¼š92%

**é«˜åº¦åŒ¹é…çš„æŠ€èƒ½ï¼š**
- **Pythonå¼€å‘**ï¼šå€™é€‰äººæœ‰5å¹´Pythonå¼€å‘ç»éªŒï¼Œå®Œå…¨ç¬¦åˆè¦æ±‚ âœ“âœ“âœ“
- **Django/Flask**ï¼šæœ‰å®é™…é¡¹ç›®ç»éªŒï¼ŒæŠ€èƒ½ç†Ÿç»ƒ âœ“âœ“âœ“
- **æ•°æ®åº“æŠ€æœ¯**ï¼šç²¾é€šMySQLã€PostgreSQLã€Redis âœ“âœ“âœ“
- **äº‘æœåŠ¡ç»éªŒ**ï¼šAWSã€é˜¿é‡Œäº‘å®æˆ˜ç»éªŒ âœ“âœ“âœ“
- **å®¹å™¨åŒ–æŠ€æœ¯**ï¼šDockerã€Kubernetesç»éªŒ âœ“âœ“âœ“

### å·¥ä½œç»éªŒåŒ¹é…åº¦ï¼š95%
- å½“å‰åœ¨é‡‘èç§‘æŠ€å…¬å¸æ‹…ä»»é«˜çº§åç«¯å·¥ç¨‹å¸ˆ
- è´Ÿè´£æ ¸å¿ƒæ”¯ä»˜ç³»ç»Ÿæ¶æ„è®¾è®¡ï¼Œä¸{real_job['company']}ä¸šåŠ¡åœºæ™¯é«˜åº¦ç›¸å…³
- æœ‰å¾®æœåŠ¡æ¶æ„æ”¹é€ ç»éªŒï¼Œç¬¦åˆç°ä»£åŒ–æŠ€æœ¯è¦æ±‚
- å¤„ç†è¿‡é«˜å¹¶å‘ç³»ç»Ÿä¼˜åŒ–ï¼ŒæŠ€æœ¯æ·±åº¦è¶³å¤Ÿ

### é¡¹ç›®ç»éªŒäº®ç‚¹ï¼š
1. **åˆ†å¸ƒå¼ä»»åŠ¡è°ƒåº¦ç³»ç»Ÿ**ï¼šå±•ç°äº†ç³»ç»Ÿæ¶æ„è®¾è®¡èƒ½åŠ›
2. **å®æ—¶æ•°æ®å¤„ç†å¹³å°**ï¼šä½“ç°äº†å¤§æ•°æ®å¤„ç†ç»éªŒ  
3. **å¾®æœåŠ¡APIç½‘å…³**ï¼šä¸ç›®æ ‡èŒä½æŠ€æœ¯æ ˆå®Œç¾åŒ¹é…

### è–ªèµ„åŒ¹é…åº¦ï¼š
- å€™é€‰äººæœŸæœ›ï¼š20-35K
- èŒä½æä¾›ï¼š{real_job['salary']}
- åŒ¹é…åº¦ï¼šå®Œå…¨ç¬¦åˆ âœ“

### åœ°ç†ä½ç½®ï¼š
- å€™é€‰äººå½“å‰ï¼šåŒ—äº¬
- èŒä½åœ°ç‚¹ï¼š{real_job['location']}
- æ— åœ°åŸŸé™åˆ¶ âœ“

## ç»¼åˆè¯„ä»·ï¼š
æå››æ˜¯{real_job['title']}èŒä½çš„ç†æƒ³å€™é€‰äººã€‚æŠ€æœ¯èƒ½åŠ›ã€å·¥ä½œç»éªŒã€é¡¹ç›®èƒŒæ™¯éƒ½ä¸èŒä½è¦æ±‚é«˜åº¦åŒ¹é…ã€‚

**æ¨èå†³ç­–ï¼šå¼ºçƒˆæ¨è**
**é¢è¯•å»ºè®®ï¼šå®‰æ’æŠ€æœ¯é¢è¯•ï¼Œé‡ç‚¹è€ƒå¯Ÿå¾®æœåŠ¡æ¶æ„ç»éªŒ**
**å½•ç”¨æ¦‚ç‡ï¼š95%**"""
            
            mock_analyze.return_value = AnalysisResult(
                resume_id=resume_id,
                job_id=job_id,
                analysis_content=realistic_analysis,
                confidence_score=0.92
            )
            
            # æ‰§è¡Œåˆ†æ
            job = await self.db_manager.get_job(job_id)
            resume = await self.db_manager.get_resume(resume_id)
            
            analysis_result = await self.ai_analyzer.analyze_resume(
                resume.to_dict(), job.to_dict()
            )
            
            # ä¿å­˜åˆ†æç»“æœ
            analysis_id = await self.db_manager.save_analysis(Analysis(
                id=analysis_result.id,
                resume_id=analysis_result.resume_id,
                job_id=analysis_result.job_id,
                analysis_content=analysis_result.analysis_content,
                confidence_score=analysis_result.confidence_score
            ))
            
            self.assertIsNotNone(analysis_id)
            self.assertGreater(analysis_result.confidence_score, 0.9)
            self.assertIn("æå››", analysis_result.analysis_content)
            self.assertIn("92%", analysis_result.analysis_content)
            self.assertIn("å¼ºçƒˆæ¨è", analysis_result.analysis_content)
        
        # 4. éªŒè¯å®Œæ•´å·¥ä½œæµç»“æœ
        # æ£€æŸ¥èŒä½æ˜¯å¦æ­£ç¡®ä¿å­˜
        saved_job = await self.db_manager.get_job(job_id)
        self.assertEqual(saved_job.title, real_job['title'])
        self.assertEqual(saved_job.company, real_job['company'])
        self.assertEqual(saved_job.location, real_job['location'])
        
        # æ£€æŸ¥ç®€å†æ˜¯å¦æ­£ç¡®ä¿å­˜
        saved_resume = await self.db_manager.get_resume(resume_id)
        self.assertEqual(saved_resume.filename, real_resume["filename"])
        self.assertIn("æå››", saved_resume.content)
        self.assertIn("Python", saved_resume.content)
        
        # æ£€æŸ¥åˆ†æç»“æœæ˜¯å¦æ­£ç¡®ä¿å­˜
        saved_analysis = await self.db_manager.get_analysis(analysis_id)
        self.assertEqual(saved_analysis.resume_id, resume_id)
        self.assertEqual(saved_analysis.job_id, job_id)
        self.assertGreater(saved_analysis.confidence_score, 0.9)
        self.assertIn("æŠ€èƒ½åŒ¹é…åº¦", saved_analysis.analysis_content)
    
    async def test_batch_resume_analysis_with_real_data(self):
        """æµ‹è¯•ä½¿ç”¨çœŸå®æ•°æ®çš„æ‰¹é‡ç®€å†åˆ†æå·¥ä½œæµ"""
        if not self.real_jobs or not self.real_resumes:
            self.skipTest("çœŸå®æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨")
        
        await self.db_manager.initialize()
        
        # 1. åˆ›å»ºçœŸå®èŒä½
        real_job = self.real_jobs[0]  # Pythonåç«¯èŒä½
        job = Job(
            id=real_job['id'],
            title=real_job['title'],
            company=real_job['company'],
            url=f"https://www.lagou.com/jobs/{real_job['id']}.html",
            location=real_job['location'],
            salary=real_job['salary'],
            requirements=real_job['requirements'],
            description=real_job['description']
        )
        await self.db_manager.save_job(job)
        
        # 2. å¤„ç†å¤šä¸ªçœŸå®ç®€å†
        resume_ids = []
        for real_resume in self.real_resumes:
            resume_data = self.resume_processor.process_file(real_resume["path"])
            resume = Resume(
                id=resume_data["id"],
                filename=real_resume["filename"],
                file_path=real_resume["path"],
                content=real_resume["content"],
                parsed_data=resume_data.get("parsed_data", {})
            )
            resume_id = await self.db_manager.save_resume(resume)
            resume_ids.append(resume_id)
        
        # 3. æ‰¹é‡åˆ†æ
        with patch.object(self.ai_analyzer, 'batch_analyze_resumes') as mock_batch_analyze:
            # åŸºäºçœŸå®æ•°æ®ç”Ÿæˆä¸åŒçš„åˆ†æç»“æœ
            mock_results = []
            
            # å¼ ä¸‰ï¼ˆå‰ç«¯ï¼‰vs Pythonåç«¯èŒä½ - ä½åŒ¹é…åº¦
            zhang_analysis = f"""## å¼ ä¸‰ç®€å†ä¸{real_job['title']}èŒä½è·¨é¢†åŸŸåˆ†æ

### æŠ€èƒ½è½¬æ¢è¯„ä¼°ï¼š65%

**å¯è½¬ç§»æŠ€èƒ½ï¼š**
- **ç¼–ç¨‹åŸºç¡€**ï¼šJavaScriptç»éªŒå¯å¿«é€Ÿè½¬å‘Python âš ï¸
- **æ¡†æ¶æ€ç»´**ï¼šReact/Vueç»éªŒæœ‰åŠ©äºç†è§£Django âš ï¸
- **åç«¯äº†è§£**ï¼šæœ‰Node.jsã€MongoDBåŸºç¡€ âœ“
- **å·¥ç¨‹åŒ–ç»éªŒ**ï¼šGitã€Webpackç­‰å¼€å‘æµç¨‹ç†Ÿæ‚‰ âœ“

**éœ€è¦è¡¥å¼ºçš„æ ¸å¿ƒæŠ€èƒ½ï¼š**
- **Pythonè¯­è¨€**ï¼šéœ€è¦ç³»ç»Ÿå­¦ä¹ Pythonè¯­æ³•å’Œç‰¹æ€§
- **Djangoæ¡†æ¶**ï¼šéœ€è¦æ·±å…¥å­¦ä¹ åç«¯æ¡†æ¶
- **å…³ç³»å‹æ•°æ®åº“**ï¼šMySQL/PostgreSQLç»éªŒä¸è¶³
- **ç³»ç»Ÿæ¶æ„**ï¼šç¼ºä¹å¾®æœåŠ¡æ¶æ„ç»éªŒ

### å·¥ä½œç»éªŒè¯„ä¼°ï¼š60%
- 3å¹´å‰ç«¯å¼€å‘ç»éªŒï¼ŒæŠ€æœ¯åŸºç¡€æ‰å®
- éœ€è¦ä»å‰ç«¯è½¬å‘åç«¯å¼€å‘
- å­¦ä¹ èƒ½åŠ›å¼ºï¼Œæœ‰è½¬å²—æ½œåŠ›

### è½¬å²—å¯è¡Œæ€§åˆ†æï¼š
**ä¼˜åŠ¿ï¼š** å¹´è½»æœ‰æ´»åŠ›ï¼Œå­¦ä¹ èƒ½åŠ›å¼ºï¼Œæœ‰ä¸€å®šåç«¯åŸºç¡€
**æŒ‘æˆ˜ï¼š** éœ€è¦3-6ä¸ªæœˆçš„æŠ€èƒ½è½¬æ¢æœŸ
**å»ºè®®ï¼š** å¦‚æœå…¬å¸æœ‰åŸ¹è®­è®¡åˆ’ï¼Œå¯ä»¥è€ƒè™‘

**å½“å‰åŒ¹é…åº¦ï¼š65%**
**è½¬å²—å»ºè®®ï¼šä¸­ç­‰å¯è¡Œï¼ˆéœ€è¦åŸ¹è®­æ”¯æŒï¼‰**"""
            
            # æå››ï¼ˆåç«¯ï¼‰vs Pythonåç«¯èŒä½ - é«˜åŒ¹é…åº¦
            li_analysis = f"""## æå››ç®€å†ä¸{real_job['title']}èŒä½ä¸“ä¸šåŒ¹é…åˆ†æ

### æŠ€èƒ½å®Œç¾åŒ¹é…ï¼š92%

**æ ¸å¿ƒæŠ€èƒ½é«˜åº¦å»åˆï¼š**
- **Pythonå¼€å‘**ï¼š5å¹´ä¸°å¯Œç»éªŒï¼ŒæŠ€æœ¯æ·±åº¦ä¼˜ç§€ âœ“âœ“âœ“
- **Django/Flask**ï¼šé¡¹ç›®å®æˆ˜ç»éªŒä¸°å¯Œ âœ“âœ“âœ“
- **æ•°æ®åº“æŠ€æœ¯**ï¼šMySQLã€PostgreSQLã€Rediså…¨æŒæ¡ âœ“âœ“âœ“
- **äº‘æœåŠ¡**ï¼šAWSã€é˜¿é‡Œäº‘å®æˆ˜ç»éªŒ âœ“âœ“âœ“
- **æ¶æ„è®¾è®¡**ï¼šå¾®æœåŠ¡ã€åˆ†å¸ƒå¼ç³»ç»Ÿç»éªŒ âœ“âœ“âœ“

### å·¥ä½œç»éªŒå®Œå…¨ç¬¦åˆï¼š95%
- å½“å‰é‡‘èç§‘æŠ€å…¬å¸é«˜çº§åç«¯å·¥ç¨‹å¸ˆ
- æ ¸å¿ƒæ”¯ä»˜ç³»ç»Ÿæ¶æ„è´Ÿè´£äºº
- é«˜å¹¶å‘ç³»ç»Ÿä¼˜åŒ–ä¸“å®¶
- å›¢é˜Ÿåä½œå’Œé¡¹ç›®ç®¡ç†ç»éªŒä¸°å¯Œ

### é¡¹ç›®ç»éªŒçªå‡ºï¼š
1. **åˆ†å¸ƒå¼ä»»åŠ¡è°ƒåº¦ç³»ç»Ÿ** - æ¶æ„èƒ½åŠ›ä½“ç°
2. **å®æ—¶æ•°æ®å¤„ç†å¹³å°** - å¤§æ•°æ®å¤„ç†èƒ½åŠ›
3. **å¾®æœåŠ¡APIç½‘å…³** - ä¸èŒä½éœ€æ±‚å®Œç¾åŒ¹é…

### ç»¼åˆè¯„ä»·ï¼š
æå››æ˜¯{real_job['company']}çš„ç†æƒ³äººé€‰ï¼Œæ— è®ºæ˜¯æŠ€æœ¯èƒ½åŠ›ã€å·¥ä½œç»éªŒè¿˜æ˜¯é¡¹ç›®èƒŒæ™¯éƒ½ä¸èŒä½è¦æ±‚é«˜åº¦åŒ¹é…ã€‚

**æ¨èå†³ç­–ï¼šå¼ºçƒˆæ¨èï¼Œä¼˜å…ˆé¢è¯•**
**å½•ç”¨å»ºè®®ï¼šå¿«é€Ÿæ¨è¿›é¢è¯•æµç¨‹**
**åŒ¹é…åº¦ï¼š92%**"""
            
            mock_results = [
                AnalysisResult(
                    resume_id=resume_ids[0],  # å¼ ä¸‰
                    job_id=real_job['id'],
                    analysis_content=zhang_analysis,
                    confidence_score=0.65
                ),
                AnalysisResult(
                    resume_id=resume_ids[1],  # æå››
                    job_id=real_job['id'],
                    analysis_content=li_analysis,
                    confidence_score=0.92
                )
            ]
            mock_batch_analyze.return_value = mock_results
            
            # æ‰§è¡Œæ‰¹é‡åˆ†æ
            resumes = [await self.db_manager.get_resume(rid) for rid in resume_ids]
            job_dict = job.to_dict()
            
            analysis_results = await self.ai_analyzer.batch_analyze_resumes(
                [r.to_dict() for r in resumes], job_dict
            )
            
            # ä¿å­˜åˆ†æç»“æœ
            for result in analysis_results:
                await self.db_manager.save_analysis(Analysis(
                    id=result.id,
                    resume_id=result.resume_id,
                    job_id=result.job_id,
                    analysis_content=result.analysis_content,
                    confidence_score=result.confidence_score
                ))
            
            # 4. éªŒè¯æ‰¹é‡åˆ†æç»“æœ
            self.assertEqual(len(analysis_results), 2)
            
            # éªŒè¯å¼ ä¸‰çš„ç»“æœï¼ˆè·¨é¢†åŸŸï¼Œä¸­ç­‰åŒ¹é…åº¦ï¼‰
            zhang_result = next(r for r in analysis_results if "å¼ ä¸‰" in r.analysis_content)
            self.assertIn("65%", zhang_result.analysis_content)
            self.assertIn("è½¬å²—", zhang_result.analysis_content)
            self.assertLess(zhang_result.confidence_score, 0.7)
            
            # éªŒè¯æå››çš„ç»“æœï¼ˆä¸“ä¸šåŒ¹é…ï¼Œé«˜åŒ¹é…åº¦ï¼‰
            li_result = next(r for r in analysis_results if "æå››" in r.analysis_content)
            self.assertIn("92%", li_result.analysis_content)
            self.assertIn("å¼ºçƒˆæ¨è", li_result.analysis_content)
            self.assertGreater(li_result.confidence_score, 0.9)
            
            # éªŒè¯æ•°æ®åº“ä¸­çš„åˆ†æè®°å½•
            job_analyses = await self.db_manager.get_analyses_by_job(real_job['id'])
            self.assertEqual(len(job_analyses), 2)
    
    async def test_cross_domain_matching_workflow(self):
        """æµ‹è¯•è·¨é¢†åŸŸåŒ¹é…å·¥ä½œæµ"""
        if not self.real_jobs or not self.real_resumes:
            self.skipTest("çœŸå®æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨")
        
        await self.db_manager.initialize()
        
        # ä½¿ç”¨AIç®—æ³•å·¥ç¨‹å¸ˆèŒä½
        ai_job = self.real_jobs[1] if len(self.real_jobs) > 1 else self.real_jobs[0]
        
        # åˆ›å»ºAIèŒä½
        job = Job(
            id=ai_job['id'],
            title=ai_job['title'],
            company=ai_job['company'],
            url=f"https://www.lagou.com/jobs/{ai_job['id']}.html",
            requirements=ai_job['requirements'],
            description=ai_job['description']
        )
        await self.db_manager.save_job(job)
        
        # ä½¿ç”¨åç«¯å¼€å‘ç®€å†ï¼ˆæå››ï¼‰æµ‹è¯•è·¨é¢†åŸŸåŒ¹é…
        backend_resume = self.real_resumes[1]  # æå››çš„åç«¯ç®€å†
        resume_data = self.resume_processor.process_file(backend_resume["path"])
        resume = Resume(
            id=resume_data["id"],
            filename=backend_resume["filename"],
            content=backend_resume["content"],
            parsed_data=resume_data.get("parsed_data", {})
        )
        await self.db_manager.save_resume(resume)
        
        # è·¨é¢†åŸŸåˆ†æ
        with patch.object(self.ai_analyzer, 'analyze_resume') as mock_analyze:
            cross_domain_analysis = f"""## è·¨é¢†åŸŸåˆ†æï¼šåç«¯å·¥ç¨‹å¸ˆ â†’ {ai_job['title']}

### æŠ€èƒ½è¿ç§»æ½œåŠ›è¯„ä¼°ï¼š75%

**å¯è¿ç§»çš„æŠ€æœ¯åŸºç¡€ï¼š**
- **ç¼–ç¨‹èƒ½åŠ›**ï¼šPythonåŸºç¡€æ‰å®ï¼Œè½¬å‘AIå¼€å‘æœ‰ä¼˜åŠ¿ âœ“âœ“
- **æ•°æ®å¤„ç†**ï¼šæœ‰å®æ—¶æ•°æ®å¤„ç†å¹³å°ç»éªŒ âœ“âœ“
- **ç³»ç»Ÿæ¶æ„**ï¼šåˆ†å¸ƒå¼ç³»ç»Ÿç»éªŒæœ‰åŠ©äºAIç³»ç»Ÿè®¾è®¡ âœ“
- **å·¥ç¨‹åŒ–èƒ½åŠ›**ï¼šDockerã€äº‘æœåŠ¡ç»éªŒç›´æ¥é€‚ç”¨ âœ“âœ“

**éœ€è¦è¡¥å¼ºçš„AIä¸“ä¸šæŠ€èƒ½ï¼š**
- **æœºå™¨å­¦ä¹ æ¡†æ¶**ï¼šéœ€è¦å­¦ä¹ TensorFlow/PyTorch âš ï¸
- **ç®—æ³•ç†è®º**ï¼šç¼ºä¹æ·±åº¦å­¦ä¹ ç†è®ºåŸºç¡€ âš ï¸
- **æ•°æ®ç§‘å­¦**ï¼šéœ€è¦è¡¥å……ç»Ÿè®¡å­¦å’Œæ•°æ®åˆ†ææŠ€èƒ½ âš ï¸
- **AIé¡¹ç›®ç»éªŒ**ï¼šç¼ºä¹å®é™…AIé¡¹ç›®ç»éªŒ âš ï¸

### è½¬å‹å¯è¡Œæ€§åˆ†æï¼š
**ä¼˜åŠ¿ï¼š**
1. æ‰å®çš„ç¼–ç¨‹åŸºç¡€ï¼Œå­¦ä¹ èƒ½åŠ›å¼º
2. æœ‰å¤§æ•°æ®å¤„ç†ç»éªŒï¼Œä¸AIæ•°æ®å¤„ç†ç›¸å…³
3. ç³»ç»Ÿæ¶æ„ç»éªŒæœ‰åŠ©äºAIç³»ç»Ÿå·¥ç¨‹åŒ–

**æŒ‘æˆ˜ï¼š**
1. éœ€è¦ç³»ç»Ÿå­¦ä¹ æœºå™¨å­¦ä¹ ç†è®º
2. ç¼ºä¹AIé¡¹ç›®å®æˆ˜ç»éªŒ
3. éœ€è¦6-12ä¸ªæœˆçš„æŠ€èƒ½è½¬æ¢æœŸ

### å»ºè®®ï¼š
- å¦‚æœå€™é€‰äººæœ‰å¼ºçƒˆçš„AIè½¬å‹æ„æ„¿ï¼Œå¯ä»¥è€ƒè™‘
- å»ºè®®å®‰æ’AIåŸºç¡€æŠ€èƒ½åŸ¹è®­
- åˆæœŸå¯ä»AIå·¥ç¨‹åŒ–æ–¹å‘å…¥æ‰‹

**è·¨é¢†åŸŸåŒ¹é…åº¦ï¼š75%**
**è½¬å‹å»ºè®®ï¼šå¯è¡Œä½†éœ€è¦åŸ¹è®­æ”¯æŒ**"""
            
            mock_analyze.return_value = AnalysisResult(
                resume_id=resume.id,
                job_id=job.id,
                analysis_content=cross_domain_analysis,
                confidence_score=0.75
            )
            
            # æ‰§è¡Œè·¨é¢†åŸŸåˆ†æ
            analysis_result = await self.ai_analyzer.analyze_resume(
                resume.to_dict(), job.to_dict()
            )
            
            # éªŒè¯è·¨é¢†åŸŸåˆ†æç»“æœ
            self.assertIn("è·¨é¢†åŸŸ", analysis_result.analysis_content)
            self.assertIn("75%", analysis_result.analysis_content)
            self.assertIn("è½¬å‹", analysis_result.analysis_content)
            self.assertIn("åŸ¹è®­", analysis_result.analysis_content)
            self.assertEqual(analysis_result.confidence_score, 0.75)
    
    async def test_error_recovery_with_real_scenarios(self):
        """æµ‹è¯•çœŸå®åœºæ™¯ä¸‹çš„é”™è¯¯æ¢å¤å·¥ä½œæµ"""
        await self.db_manager.initialize()
        
        # 1. æµ‹è¯•ç½‘ç»œé”™è¯¯æ¢å¤
        with patch.object(self.job_manager, 'scrape_job') as mock_scrape:
            # ä½¿ç”¨çœŸå®URLæ¨¡æ‹Ÿç½‘ç»œé”™è¯¯
            real_url = "https://www.lagou.com/jobs/network-error-test.html"
            
            # ç¬¬ä¸€æ¬¡è°ƒç”¨å¤±è´¥ï¼Œç¬¬äºŒæ¬¡æˆåŠŸ
            mock_scrape.side_effect = [
                NetworkError("ç½‘ç»œè¿æ¥è¶…æ—¶"),
                ScrapingResult(
                    url=real_url,
                    title="ç½‘ç»œæ¢å¤æµ‹è¯•èŒä½",
                    company="æµ‹è¯•å…¬å¸",
                    location="åŒ—äº¬"
                )
            ]
            
            # æ¨¡æ‹Ÿé‡è¯•æœºåˆ¶
            job_result = None
            max_retries = 2
            
            for attempt in range(max_retries):
                try:
                    job_result = await self.job_manager.scrape_job(real_url)
                    break
                except NetworkError:
                    if attempt == max_retries - 1:
                        raise
                    continue
            
            self.assertIsNotNone(job_result)
            self.assertEqual(job_result.title, "ç½‘ç»œæ¢å¤æµ‹è¯•èŒä½")
        
        # 2. æµ‹è¯•æ•°æ®åº“äº‹åŠ¡å›æ»š
        if self.real_jobs:
            real_job = self.real_jobs[0]
            job = Job(
                id=f"transaction-test-{real_job['id']}",
                title=real_job['title'],
                company=real_job['company'],
                url=f"https://test.com/transaction-test.html"
            )
            
            # æˆåŠŸä¿å­˜èŒä½
            job_id = await self.db_manager.save_job(job)
            self.assertIsNotNone(job_id)
            
            # æ¨¡æ‹Ÿäº‹åŠ¡å¤±è´¥çš„æƒ…å†µ
            try:
                async with self.db_manager.transaction() as conn:
                    # æ›´æ–°èŒä½
                    await conn.execute(
                        "UPDATE jobs SET title = ? WHERE id = ?",
                        ("æ›´æ–°åçš„æ ‡é¢˜", job_id)
                    )
                    
                    # æ¨¡æ‹Ÿå¼‚å¸¸
                    raise Exception("æ¨¡æ‹Ÿäº‹åŠ¡å¤±è´¥")
                    
            except Exception:
                pass
            
            # éªŒè¯æ•°æ®æœªè¢«æ›´æ–°ï¼ˆäº‹åŠ¡å·²å›æ»šï¼‰
            job_after_rollback = await self.db_manager.get_job(job_id)
            self.assertEqual(job_after_rollback.title, real_job['title'])  # åŸå§‹æ ‡é¢˜


class TestRealDataIntegration(unittest.TestCase):
    """çœŸå®æ•°æ®é›†æˆæµ‹è¯•"""
    
    def setUp(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        self.temp_db = tempfile.NamedTemporaryFile(delete=False, suffix='.db')
        self.temp_db.close()
        self.db_manager = DatabaseManager(self.temp_db.name)
        
        # åŠ è½½çœŸå®æ•°æ®
        self.real_jobs = load_real_jobs_data()
        self.real_resumes = load_real_resumes_data()
        self.resume_metadata, self.job_metadata = load_real_metadata()
    
    def tearDown(self):
        """æ¸…ç†æµ‹è¯•ç¯å¢ƒ"""
        asyncio.run(self.db_manager.close())
        try:
            os.unlink(self.temp_db.name)
        except OSError:
            pass
    
    async def test_real_data_persistence_and_retrieval(self):
        """æµ‹è¯•çœŸå®æ•°æ®çš„æŒä¹…åŒ–å’Œæ£€ç´¢"""
        if not self.real_jobs or not self.real_resumes:
            self.skipTest("çœŸå®æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨")
        
        await self.db_manager.initialize()
        
        # 1. ä¿å­˜æ‰€æœ‰çœŸå®èŒä½
        saved_job_ids = []
        for real_job in self.real_jobs:
            job = Job(
                id=real_job['id'],
                title=real_job['title'],
                company=real_job['company'],
                location=real_job.get('location', ''),
                salary=real_job.get('salary', ''),
                requirements=real_job.get('requirements', ''),
                description=real_job.get('description', ''),
                url=f"https://www.lagou.com/jobs/{real_job['id']}.html"
            )
            job_id = await self.db_manager.save_job(job)
            saved_job_ids.append(job_id)
        
        # éªŒè¯æ‰€æœ‰èŒä½éƒ½ä¿å­˜æˆåŠŸ
        self.assertEqual(len(saved_job_ids), len(self.real_jobs))
        
        # 2. ä¿å­˜æ‰€æœ‰çœŸå®ç®€å†
        saved_resume_ids = []
        resume_processor = ResumeProcessor()
        
        for real_resume in self.real_resumes:
            resume_data = resume_processor.process_file(real_resume["path"])
            resume = Resume(
                id=resume_data["id"],
                filename=real_resume["filename"],
                content=real_resume["content"],
                file_path=real_resume["path"],
                parsed_data=resume_data.get("parsed_data", {})
            )
            resume_id = await self.db_manager.save_resume(resume)
            saved_resume_ids.append(resume_id)
        
        # éªŒè¯æ‰€æœ‰ç®€å†éƒ½ä¿å­˜æˆåŠŸ
        self.assertEqual(len(saved_resume_ids), len(self.real_resumes))
        
        # 3. æµ‹è¯•æ•°æ®æ£€ç´¢
        # æŒ‰å…¬å¸æœç´¢èŒä½
        beijing_jobs = await self.db_manager.search_jobs(location="åŒ—äº¬")
        self.assertGreater(len(beijing_jobs), 0)
        
        # æŒ‰æŠ€èƒ½æœç´¢
        python_jobs = await self.db_manager.search_jobs(keyword="Python")
        self.assertGreater(len(python_jobs), 0)
        
        # éªŒè¯æœç´¢ç»“æœåŒ…å«çœŸå®æ•°æ®
        for job in python_jobs:
            self.assertIn("Python", job.title + job.requirements)
    
    async def test_real_data_analysis_scenarios(self):
        """æµ‹è¯•çœŸå®æ•°æ®çš„åˆ†æåœºæ™¯"""
        if not self.real_jobs or not self.real_resumes:
            self.skipTest("çœŸå®æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨")
        
        await self.db_manager.initialize()
        
        # åˆ›å»ºçœŸå®çš„åˆ†æåœºæ™¯
        analysis_scenarios = [
            {
                "job_index": 0,  # Pythonåç«¯
                "resume_index": 1,  # æå››ï¼ˆåç«¯ï¼‰
                "expected_score": 0.9,
                "scenario": "ä¸“ä¸šåŒ¹é…"
            },
            {
                "job_index": 0,  # Pythonåç«¯
                "resume_index": 0,  # å¼ ä¸‰ï¼ˆå‰ç«¯ï¼‰
                "expected_score": 0.65,
                "scenario": "è·¨é¢†åŸŸåŒ¹é…"
            }
        ]
        
        if len(self.real_jobs) > 1:
            analysis_scenarios.append({
                "job_index": 1,  # AIç®—æ³•å·¥ç¨‹å¸ˆ
                "resume_index": 1,  # æå››ï¼ˆåç«¯ï¼‰
                "expected_score": 0.75,
                "scenario": "æŠ€èƒ½è¿ç§»"
            })
        
        for scenario in analysis_scenarios:
            with self.subTest(scenario=scenario["scenario"]):
                # å‡†å¤‡èŒä½å’Œç®€å†æ•°æ®
                real_job = self.real_jobs[scenario["job_index"]]
                real_resume = self.real_resumes[scenario["resume_index"]]
                
                # ä¿å­˜èŒä½
                job = Job(
                    id=f"scenario-{real_job['id']}",
                    title=real_job['title'],
                    company=real_job['company'],
                    requirements=real_job.get('requirements', '')
                )
                await self.db_manager.save_job(job)
                
                # ä¿å­˜ç®€å†
                resume_processor = ResumeProcessor()
                resume_data = resume_processor.process_file(real_resume["path"])
                resume = Resume(
                    id=f"scenario-{resume_data['id']}",
                    filename=real_resume["filename"],
                    content=real_resume["content"]
                )
                await self.db_manager.save_resume(resume)
                
                # æ¨¡æ‹Ÿåˆ†æ
                analysis = Analysis(
                    id=f"analysis-{scenario['scenario']}",
                    job_id=job.id,
                    resume_id=resume.id,
                    analysis_content=f"{scenario['scenario']}åˆ†æç»“æœ",
                    confidence_score=scenario["expected_score"]
                )
                await self.db_manager.save_analysis(analysis)
                
                # éªŒè¯åˆ†æç»“æœ
                saved_analysis = await self.db_manager.get_analysis(analysis.id)
                self.assertEqual(saved_analysis.confidence_score, scenario["expected_score"])
                self.assertIn(scenario["scenario"], saved_analysis.analysis_content)


class TestPerformanceWithRealData(unittest.TestCase):
    """ä½¿ç”¨çœŸå®æ•°æ®çš„æ€§èƒ½æµ‹è¯•"""
    
    def setUp(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        self.temp_db = tempfile.NamedTemporaryFile(delete=False, suffix='.db')
        self.temp_db.close()
        self.db_manager = DatabaseManager(self.temp_db.name)
        
        # åŠ è½½çœŸå®æ•°æ®
        self.real_jobs = load_real_jobs_data()
        self.real_resumes = load_real_resumes_data()
    
    def tearDown(self):
        """æ¸…ç†æµ‹è¯•ç¯å¢ƒ"""
        asyncio.run(self.db_manager.close())
        try:
            os.unlink(self.temp_db.name)
        except OSError:
            pass
    
    async def test_real_data_processing_performance(self):
        """æµ‹è¯•çœŸå®æ•°æ®å¤„ç†æ€§èƒ½"""
        if not self.real_jobs or not self.real_resumes:
            self.skipTest("çœŸå®æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨")
        
        await self.db_manager.initialize()
        
        # æµ‹è¯•æ‰¹é‡æ•°æ®å¤„ç†æ€§èƒ½
        start_time = datetime.now()
        
        # æ‰¹é‡ä¿å­˜çœŸå®èŒä½
        for real_job in self.real_jobs:
            job = Job(
                id=f"perf-{real_job['id']}",
                title=real_job['title'],
                company=real_job['company'],
                requirements=real_job.get('requirements', ''),
                description=real_job.get('description', '')
            )
            await self.db_manager.save_job(job)
        
        # æ‰¹é‡ä¿å­˜çœŸå®ç®€å†
        resume_processor = ResumeProcessor()
        for real_resume in self.real_resumes:
            resume_data = resume_processor.process_file(real_resume["path"])
            resume = Resume(
                id=f"perf-{resume_data['id']}",
                filename=real_resume["filename"],
                content=real_resume["content"]
            )
            await self.db_manager.save_resume(resume)
        
        processing_time = (datetime.now() - start_time).total_seconds()
        
        # éªŒè¯æ€§èƒ½è¦æ±‚ï¼ˆæ ¹æ®æ•°æ®é‡è°ƒæ•´ï¼‰
        expected_max_time = len(self.real_jobs + self.real_resumes) * 0.5  # æ¯æ¡è®°å½•0.5ç§’
        self.assertLess(processing_time, expected_max_time)
        
        # æµ‹è¯•æŸ¥è¯¢æ€§èƒ½
        start_time = datetime.now()
        
        # æ‰§è¡Œå¤æ‚æŸ¥è¯¢
        all_jobs = await self.db_manager.get_all_jobs()
        all_resumes = await self.db_manager.get_all_resumes()
        python_jobs = await self.db_manager.search_jobs(keyword="Python")
        
        query_time = (datetime.now() - start_time).total_seconds()
        
        # éªŒè¯æŸ¥è¯¢æ€§èƒ½
        self.assertLess(query_time, 2.0)  # æŸ¥è¯¢åº”åœ¨2ç§’å†…å®Œæˆ
        
        # éªŒè¯æŸ¥è¯¢ç»“æœ
        self.assertEqual(len(all_jobs), len(self.real_jobs))
        self.assertEqual(len(all_resumes), len(self.real_resumes))
        self.assertGreater(len(python_jobs), 0)


def run_integration_tests():
    """è¿è¡Œé›†æˆæµ‹è¯•"""
    print("ğŸ”§ è¿è¡Œç«¯åˆ°ç«¯å·¥ä½œæµé›†æˆæµ‹è¯•ï¼ˆä½¿ç”¨çœŸå®æ•°æ®ï¼‰...")
    
    # åˆ›å»ºæµ‹è¯•å¥—ä»¶
    test_suite = unittest.TestSuite()
    
    # æ·»åŠ æµ‹è¯•ç±»
    test_classes = [
        TestEndToEndWorkflow,
        TestRealDataIntegration,
        TestPerformanceWithRealData
    ]
    
    for test_class in test_classes:
        tests = unittest.TestLoader().loadTestsFromTestCase(test_class)
        test_suite.addTests(tests)
    
    # è¿è¡Œæµ‹è¯•
    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(test_suite)
    
    return result.wasSuccessful()


if __name__ == "__main__":
    success = run_integration_tests()
    print(f"\n{'âœ… æµ‹è¯•é€šè¿‡' if success else 'âŒ æµ‹è¯•å¤±è´¥'}")