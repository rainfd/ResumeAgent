"""Adapters for integrating core modules with Web interface."""

import asyncio
import streamlit as st
from typing import Dict, Any, List, Optional
from pathlib import Path
import tempfile
import os

from ..core.scraper import JobScraper
from ..core.parser import ResumeParser
from ..core.ai_analyzer import AIAnalyzer
from ..core.job_manager import JobManager
from ..core.resume_processor import ResumeProcessor
from .session_manager import SessionManager
from ..data.database import get_database_manager
from ..utils import get_logger

logger = get_logger(__name__)

class WebJobManager:
    """Webç•Œé¢èŒä½ç®¡ç†é€‚é…å™¨"""
    
    def __init__(self):
        self.job_manager = JobManager()
        self.scraper = JobScraper()
        self.db_manager = get_database_manager()
    
    @st.cache_data(ttl=300)  # ç¼“å­˜5åˆ†é’Ÿ
    def scrape_job(self, url: str) -> Dict[str, Any]:
        """çˆ¬å–èŒä½ä¿¡æ¯"""
        try:
            SessionManager.set_loading_state('job_scraping', True)
            
            # åˆ›å»ºè¿›åº¦æ¡
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            # æ¨¡æ‹Ÿçˆ¬å–è¿›åº¦
            status_text.text("æ­£åœ¨åˆå§‹åŒ–çˆ¬è™«...")
            progress_bar.progress(0.2)
            
            status_text.text("æ­£åœ¨è®¿é—®èŒä½é¡µé¢...")
            progress_bar.progress(0.4)
            
            # å®é™…çˆ¬å– (è¿™é‡Œéœ€è¦é€‚é…å¼‚æ­¥)
            job_info = asyncio.run(self.scraper.scrape_job(url))
            
            status_text.text("æ­£åœ¨è§£æèŒä½ä¿¡æ¯...")
            progress_bar.progress(0.8)
            
            status_text.text("çˆ¬å–å®Œæˆï¼")
            progress_bar.progress(1.0)
            
            # æ¸…ç†UI
            progress_bar.empty()
            status_text.empty()
            
            return job_info.__dict__ if job_info else {}
            
        except Exception as e:
            logger.error(f"Job scraping error: {e}")
            st.error(f"èŒä½çˆ¬å–å¤±è´¥: {str(e)}")
            return {}
        finally:
            SessionManager.set_loading_state('job_scraping', False)
    
    def get_jobs_list(self) -> List[Dict[str, Any]]:
        """è·å–èŒä½åˆ—è¡¨"""
        return st.session_state.jobs
    
    def add_job_to_session(self, job_data: Dict[str, Any]) -> bool:
        """æ·»åŠ èŒä½åˆ°ä¼šè¯å¹¶ä¿å­˜åˆ°æ•°æ®åº“"""
        # æ·»åŠ åˆ°ä¼šè¯çŠ¶æ€
        success = SessionManager.add_job(job_data)
        
        if success:
            # å¼‚æ­¥ä¿å­˜åˆ°æ•°æ®åº“
            try:
                asyncio.create_task(self.db_manager.save_job(job_data))
            except Exception as e:
                logger.error(f"Failed to save job to database: {e}")
        
        return success
    
    def remove_job_from_session(self, job_id: int) -> bool:
        """ä»ä¼šè¯ä¸­åˆ é™¤èŒä½"""
        return SessionManager.remove_job(job_id)

class WebResumeManager:
    """Webç•Œé¢ç®€å†ç®¡ç†é€‚é…å™¨"""
    
    def __init__(self):
        self.resume_processor = ResumeProcessor()
        self.parser = ResumeParser()
        self.db_manager = get_database_manager()
    
    def process_uploaded_file(self, uploaded_file) -> Optional[Dict[str, Any]]:
        """å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶"""
        if not uploaded_file:
            return None
        
        try:
            SessionManager.set_loading_state('resume_parsing', True)
            
            # åˆ›å»ºè¿›åº¦æ¡
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            status_text.text("æ­£åœ¨ä¿å­˜æ–‡ä»¶...")
            progress_bar.progress(0.2)
            
            # ä¿å­˜ä¸´æ—¶æ–‡ä»¶
            with tempfile.NamedTemporaryFile(delete=False, suffix=f".{uploaded_file.name.split('.')[-1]}") as tmp_file:
                tmp_file.write(uploaded_file.getvalue())
                tmp_file_path = tmp_file.name
            
            status_text.text("æ­£åœ¨è§£æç®€å†...")
            progress_bar.progress(0.5)
            
            # æ ¹æ®æ–‡ä»¶ç±»å‹è§£æ
            file_extension = uploaded_file.name.split('.')[-1].lower()
            
            try:
                # ä½¿ç”¨ç»Ÿä¸€çš„parse_fileæ–¹æ³•
                parsed_resume = self.parser.parse_file(tmp_file_path)
            except Exception as e:
                st.error(f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹æˆ–è§£æå¤±è´¥: {file_extension} - {str(e)}")
                return None
            
            status_text.text("æ­£åœ¨ç»“æ„åŒ–æ•°æ®...")
            progress_bar.progress(0.8)
            
            # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
            resume_dict = {
                'name': uploaded_file.name,
                'file_path': parsed_resume.file_path,
                'content': parsed_resume.raw_text,
                'personal_info': parsed_resume.personal_info,
                'education': parsed_resume.education,
                'experience': parsed_resume.work_experience,
                'projects': parsed_resume.projects,
                'skills': parsed_resume.skills,
                'file_type': file_extension,
                'file_size': len(uploaded_file.getvalue()),
                'sections': [{'title': s.title, 'content': s.content} for s in parsed_resume.sections]
            }
            
            status_text.text("è§£æå®Œæˆï¼")
            progress_bar.progress(1.0)
            
            # æ¸…ç†UIå’Œä¸´æ—¶æ–‡ä»¶
            progress_bar.empty()
            status_text.empty()
            os.unlink(tmp_file_path)  # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
            
            return resume_dict
            
        except Exception as e:
            logger.error(f"Resume parsing error: {e}")
            st.error(f"ç®€å†è§£æå¤±è´¥: {str(e)}")
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if 'tmp_file_path' in locals():
                try:
                    os.unlink(tmp_file_path)
                except:
                    pass
            return None
        finally:
            SessionManager.set_loading_state('resume_parsing', False)
    
    def get_resumes_list(self) -> List[Dict[str, Any]]:
        """è·å–ç®€å†åˆ—è¡¨"""
        return st.session_state.resumes
    
    def add_resume_to_session(self, resume_data: Dict[str, Any]) -> bool:
        """æ·»åŠ ç®€å†åˆ°ä¼šè¯å¹¶ä¿å­˜åˆ°æ•°æ®åº“"""
        # æ·»åŠ åˆ°ä¼šè¯çŠ¶æ€
        success = SessionManager.add_resume(resume_data)
        
        if success:
            # å¼‚æ­¥ä¿å­˜åˆ°æ•°æ®åº“
            try:
                asyncio.create_task(self.db_manager.save_resume(resume_data))
            except Exception as e:
                logger.error(f"Failed to save resume to database: {e}")
        
        return success
    
    def remove_resume_from_session(self, resume_id: int) -> bool:
        """ä»ä¼šè¯ä¸­åˆ é™¤ç®€å†"""
        return SessionManager.remove_resume(resume_id)
    
    def preview_resume(self, resume_data: Dict[str, Any]):
        """é¢„è§ˆç®€å†å†…å®¹"""
        st.subheader("ğŸ“„ ç®€å†é¢„è§ˆ")
        
        # åŸºæœ¬ä¿¡æ¯
        col1, col2 = st.columns(2)
        with col1:
            st.metric("æ–‡ä»¶å", resume_data.get('name', 'Unknown'))
            st.metric("æ–‡ä»¶ç±»å‹", resume_data.get('file_type', 'Unknown'))
        with col2:
            st.metric("æ–‡ä»¶å¤§å°", f"{resume_data.get('file_size', 0)} bytes")
            st.metric("æŠ€èƒ½æ•°é‡", len(resume_data.get('skills', [])))
        
        # å†…å®¹é¢„è§ˆ
        with st.expander("ğŸ“ ç®€å†å†…å®¹", expanded=True):
            content = resume_data.get('content', '')
            st.text_area(
                "å†…å®¹é¢„è§ˆ",
                value=content[:1000] + "..." if len(content) > 1000 else content,
                height=200,
                disabled=True
            )
        
        # ç»“æ„åŒ–ä¿¡æ¯
        if resume_data.get('skills'):
            with st.expander("ğŸ› ï¸ æŠ€èƒ½æ¸…å•"):
                st.write(", ".join(resume_data.get('skills', [])))
        
        if resume_data.get('experience'):
            with st.expander("ğŸ’¼ å·¥ä½œç»éªŒ"):
                for exp in resume_data.get('experience', []):
                    st.write(f"- {exp}")

class WebAnalysisManager:
    """Webç•Œé¢åˆ†æç®¡ç†é€‚é…å™¨"""
    
    def __init__(self):
        self.ai_analyzer = AIAnalyzer()
        self.db_manager = get_database_manager()
    
    def analyze_match(self, job_data: Dict[str, Any], resume_data: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """åˆ†æåŒ¹é…åº¦"""
        if not job_data or not resume_data:
            st.error("è¯·å…ˆé€‰æ‹©èŒä½å’Œç®€å†")
            return None
        
        try:
            SessionManager.set_loading_state('analysis', True)
            
            # åˆ›å»ºè¿›åº¦æ¡
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            status_text.text("æ­£åœ¨è¿æ¥AIæœåŠ¡...")
            progress_bar.progress(0.2)
            
            status_text.text("æ­£åœ¨åˆ†æèŒä½è¦æ±‚...")
            progress_bar.progress(0.4)
            
            status_text.text("æ­£åœ¨åˆ†æç®€å†å†…å®¹...")
            progress_bar.progress(0.6)
            
            # æ‰§è¡ŒAIåˆ†æ
            # è¿™é‡Œéœ€è¦é€‚é…ç°æœ‰çš„AIåˆ†æå™¨
            analysis_result = {
                'job_id': job_data.get('id'),
                'resume_id': resume_data.get('id'),
                'overall_score': 0.78,
                'skill_match_score': 0.85,
                'experience_score': 0.72,
                'keyword_coverage': 0.68,
                'missing_skills': ['Docker', 'Kubernetes', 'Redis'],
                'strengths': ['Python', 'Django', 'MySQL', 'å›¢é˜Ÿåä½œ'],
                'suggestions': [
                    {
                        'section': 'æŠ€èƒ½æ¸…å•',
                        'original': 'ç†Ÿæ‚‰Pythonå¼€å‘',
                        'suggested': 'ç²¾é€šPythonå¼€å‘ï¼Œæœ‰3å¹´é¡¹ç›®ç»éªŒ',
                        'reason': 'æ›´å…·ä½“åœ°æè¿°æŠ€èƒ½æ°´å¹³å’Œç»éªŒ'
                    }
                ]
            }
            
            status_text.text("æ­£åœ¨ç”Ÿæˆåˆ†ææŠ¥å‘Š...")
            progress_bar.progress(0.9)
            
            status_text.text("åˆ†æå®Œæˆï¼")
            progress_bar.progress(1.0)
            
            # æ¸…ç†UI
            progress_bar.empty()
            status_text.empty()
            
            return analysis_result
            
        except Exception as e:
            logger.error(f"Analysis error: {e}")
            st.error(f"åˆ†æå¤±è´¥: {str(e)}")
            return None
        finally:
            SessionManager.set_loading_state('analysis', False)
    
    def get_analyses_list(self) -> List[Dict[str, Any]]:
        """è·å–åˆ†æåˆ—è¡¨"""
        return st.session_state.analyses
    
    def add_analysis_to_session(self, analysis_data: Dict[str, Any]) -> bool:
        """æ·»åŠ åˆ†æç»“æœåˆ°ä¼šè¯å¹¶ä¿å­˜åˆ°æ•°æ®åº“"""
        # æ·»åŠ åˆ°ä¼šè¯çŠ¶æ€
        success = SessionManager.add_analysis(analysis_data)
        
        if success:
            # å¼‚æ­¥ä¿å­˜åˆ°æ•°æ®åº“
            try:
                asyncio.create_task(self.db_manager.save_analysis(analysis_data))
            except Exception as e:
                logger.error(f"Failed to save analysis to database: {e}")
        
        return success
    
    def display_analysis_results(self, analysis_data: Dict[str, Any]):
        """æ˜¾ç¤ºåˆ†æç»“æœ"""
        from .components import UIComponents
        
        components = UIComponents()
        
        # åŒ¹é…åº¦è¯„åˆ†
        st.subheader("ğŸ“Š åŒ¹é…åº¦è¯„åˆ†")
        scores = {
            "æ€»ä½“åŒ¹é…åº¦": analysis_data.get('overall_score', 0),
            "æŠ€èƒ½åŒ¹é…": analysis_data.get('skill_match_score', 0),
            "ç»éªŒåŒ¹é…": analysis_data.get('experience_score', 0),
            "å…³é”®è¯è¦†ç›–": analysis_data.get('keyword_coverage', 0)
        }
        components.render_match_score_chart(scores)
        
        # ç¼ºå¤±æŠ€èƒ½
        missing_skills = analysis_data.get('missing_skills', [])
        if missing_skills:
            st.subheader("âš ï¸ ç¼ºå¤±æŠ€èƒ½")
            for skill in missing_skills:
                st.warning(f"å»ºè®®è¡¥å……: {skill}")
        
        # ä¼˜åŠ¿é¡¹
        strengths = analysis_data.get('strengths', [])
        if strengths:
            st.subheader("âœ… ä¼˜åŠ¿é¡¹")
            for strength in strengths:
                st.success(f"åŒ¹é…è‰¯å¥½: {strength}")
        
        # ä¼˜åŒ–å»ºè®®
        suggestions = analysis_data.get('suggestions', [])
        if suggestions:
            st.subheader("ğŸ’¡ ä¼˜åŒ–å»ºè®®")
            for suggestion in suggestions:
                with st.expander(f"ä¼˜åŒ– {suggestion.get('section', 'Unknown')}"):
                    components.render_text_diff(
                        suggestion.get('original', ''),
                        suggestion.get('suggested', ''),
                        "ä¿®æ”¹å»ºè®®"
                    )
                    st.info(f"**ç†ç”±**: {suggestion.get('reason', '')}")

class WebGreetingManager:
    """Webç•Œé¢æ‰“æ‹›å‘¼è¯­ç®¡ç†é€‚é…å™¨"""
    
    def __init__(self):
        pass
    
    def generate_greeting(self, job_data: Dict[str, Any], resume_data: Dict[str, Any]) -> List[str]:
        """ç”Ÿæˆæ‰“æ‹›å‘¼è¯­"""
        if not job_data or not resume_data:
            st.error("è¯·å…ˆé€‰æ‹©èŒä½å’Œç®€å†")
            return []
        
        try:
            SessionManager.set_loading_state('greeting_generation', True)
            
            # æ¨¡æ‹Ÿç”Ÿæˆè¿‡ç¨‹
            with st.spinner("æ­£åœ¨ç”Ÿæˆä¸ªæ€§åŒ–æ‰“æ‹›å‘¼è¯­..."):
                # è¿™é‡Œå°†æ¥é›†æˆAIç”Ÿæˆé€»è¾‘
                greetings = [
                    f"æ‚¨å¥½ï¼æˆ‘å¯¹{job_data.get('company', '')}çš„{job_data.get('title', '')}èŒä½éå¸¸æ„Ÿå…´è¶£...",
                    f"å°Šæ•¬çš„HRï¼Œæˆ‘æ˜¯ä¸€åæœ‰ç»éªŒçš„å¼€å‘è€…ï¼Œå¸Œæœ›èƒ½åŠ å…¥{job_data.get('company', '')}å›¢é˜Ÿ...",
                    f"Hello! æˆ‘åœ¨æ‹›è˜ç½‘ç«™ä¸Šçœ‹åˆ°è´µå…¬å¸çš„{job_data.get('title', '')}èŒä½æ‹›è˜..."
                ]
            
            return greetings
            
        except Exception as e:
            logger.error(f"Greeting generation error: {e}")
            st.error(f"ç”Ÿæˆæ‰“æ‹›å‘¼è¯­å¤±è´¥: {str(e)}")
            return []
        finally:
            SessionManager.set_loading_state('greeting_generation', False)