"""æ€§èƒ½ç›‘æ§å’Œä¼˜åŒ–

é›†æˆå¼‚æ­¥å¤„ç†ã€ç¼“å­˜ç®¡ç†å’Œé”™è¯¯å¤„ç†çš„ç»Ÿä¸€æ€§èƒ½ä¼˜åŒ–ç³»ç»Ÿã€‚
"""

import streamlit as st
import time
import psutil
import threading
from typing import Dict, Any, Optional, List, Callable
from datetime import datetime, timedelta
from dataclasses import dataclass, field
from functools import wraps
import asyncio
import resource
import gc

from .async_utils import get_async_manager, run_async_operation_with_ui
from .cache_manager import get_cache_manager, schedule_cache_cleanup, st_cache
from .error_handler import get_error_handler, handle_errors, track_operation
from ..utils import get_logger

logger = get_logger(__name__)

@dataclass
class PerformanceMetrics:
    """æ€§èƒ½æŒ‡æ ‡"""
    timestamp: datetime = field(default_factory=datetime.now)
    cpu_percent: float = 0.0
    memory_mb: float = 0.0
    memory_percent: float = 0.0
    cache_hit_rate: float = 0.0
    cache_size_mb: float = 0.0
    active_operations: int = 0
    error_count: int = 0
    response_time_ms: float = 0.0
    session_count: int = 0

class PerformanceMonitor:
    """æ€§èƒ½ç›‘æ§å™¨"""
    
    def __init__(self, max_history_points: int = 1000):
        self.max_history_points = max_history_points
        self.metrics_history: List[PerformanceMetrics] = []
        self.start_time = datetime.now()
        self.last_cleanup = datetime.now()
        
        # æ€§èƒ½é˜ˆå€¼
        self.thresholds = {
            'cpu_percent': 80.0,
            'memory_percent': 85.0,
            'cache_hit_rate': 0.5,  # 50%
            'response_time_ms': 5000.0,  # 5ç§’
            'error_rate': 0.1  # 10%
        }
        
        # å¯åŠ¨å®šæœŸç›‘æ§
        self._start_monitoring()
    
    def _start_monitoring(self):
        """å¯åŠ¨åå°ç›‘æ§"""
        def monitor_loop():
            while True:
                try:
                    metrics = self.collect_metrics()
                    self.add_metrics(metrics)
                    
                    # æ£€æŸ¥æ€§èƒ½é˜ˆå€¼
                    self.check_performance_thresholds(metrics)
                    
                    # è‡ªåŠ¨ä¼˜åŒ–
                    self.auto_optimize(metrics)
                    
                    time.sleep(30)  # æ¯30ç§’æ”¶é›†ä¸€æ¬¡
                except Exception as e:
                    logger.error(f"Performance monitoring error: {e}")
                    time.sleep(60)  # å‡ºé”™æ—¶ç­‰å¾…æ›´ä¹…
        
        # åœ¨åå°çº¿ç¨‹ä¸­è¿è¡Œç›‘æ§
        monitor_thread = threading.Thread(target=monitor_loop, daemon=True)
        monitor_thread.start()
    
    def collect_metrics(self) -> PerformanceMetrics:
        """æ”¶é›†æ€§èƒ½æŒ‡æ ‡"""
        try:
            # ç³»ç»ŸæŒ‡æ ‡
            cpu_percent = psutil.cpu_percent(interval=1)
            memory = psutil.virtual_memory()
            
            # ç¼“å­˜æŒ‡æ ‡
            cache_manager = get_cache_manager()
            cache_stats = cache_manager.get_stats()
            
            # å¼‚æ­¥æ“ä½œæŒ‡æ ‡
            async_manager = get_async_manager()
            active_ops = len([op for op in async_manager.operations.values() 
                            if op.status == "running"])
            
            # é”™è¯¯æŒ‡æ ‡
            error_handler = get_error_handler()
            recent_errors = len([e for e in error_handler.get_error_history(50)
                               if (datetime.now() - e['timestamp']).seconds < 3600])
            
            # SessionæŒ‡æ ‡
            session_count = len(st.session_state) if hasattr(st, 'session_state') else 0
            
            return PerformanceMetrics(
                cpu_percent=cpu_percent,
                memory_mb=memory.used / (1024 * 1024),
                memory_percent=memory.percent,
                cache_hit_rate=cache_stats.get('hit_rate', 0.0),
                cache_size_mb=cache_stats.get('size_mb', 0.0),
                active_operations=active_ops,
                error_count=recent_errors,
                session_count=session_count
            )
            
        except Exception as e:
            logger.error(f"Failed to collect metrics: {e}")
            return PerformanceMetrics()
    
    def add_metrics(self, metrics: PerformanceMetrics):
        """æ·»åŠ æŒ‡æ ‡åˆ°å†å²è®°å½•"""
        self.metrics_history.append(metrics)
        
        # é™åˆ¶å†å²è®°å½•å¤§å°
        if len(self.metrics_history) > self.max_history_points:
            self.metrics_history = self.metrics_history[-self.max_history_points:]
    
    def check_performance_thresholds(self, metrics: PerformanceMetrics):
        """æ£€æŸ¥æ€§èƒ½é˜ˆå€¼"""
        alerts = []
        
        if metrics.cpu_percent > self.thresholds['cpu_percent']:
            alerts.append(f"CPUä½¿ç”¨ç‡è¿‡é«˜: {metrics.cpu_percent:.1f}%")
        
        if metrics.memory_percent > self.thresholds['memory_percent']:
            alerts.append(f"å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜: {metrics.memory_percent:.1f}%")
        
        if metrics.cache_hit_rate < self.thresholds['cache_hit_rate']:
            alerts.append(f"ç¼“å­˜å‘½ä¸­ç‡è¿‡ä½: {metrics.cache_hit_rate:.1%}")
        
        if metrics.response_time_ms > self.thresholds['response_time_ms']:
            alerts.append(f"å“åº”æ—¶é—´è¿‡é•¿: {metrics.response_time_ms:.0f}ms")
        
        # è®°å½•è­¦å‘Š
        for alert in alerts:
            logger.warning(f"Performance alert: {alert}")
    
    def auto_optimize(self, metrics: PerformanceMetrics):
        """è‡ªåŠ¨ä¼˜åŒ–"""
        try:
            # å†…å­˜æ¸…ç†
            if metrics.memory_percent > 80:
                self._cleanup_memory()
            
            # ç¼“å­˜æ¸…ç†
            if metrics.cache_size_mb > 50:  # 50MB
                cache_manager = get_cache_manager()
                cache_manager.cleanup_expired()
            
            # é”™è¯¯å†å²æ¸…ç†
            if metrics.error_count > 100:
                error_handler = get_error_handler()
                error_handler.clear_error_history()
                
        except Exception as e:
            logger.error(f"Auto optimization failed: {e}")
    
    def _cleanup_memory(self):
        """æ¸…ç†å†…å­˜"""
        # å¼ºåˆ¶åƒåœ¾å›æ”¶
        gc.collect()
        
        # æ¸…ç†ç¼“å­˜
        cache_manager = get_cache_manager()
        cleaned = cache_manager.cleanup_expired()
        
        if cleaned > 0:
            logger.info(f"Memory cleanup: removed {cleaned} cache entries")
    
    def get_current_metrics(self) -> PerformanceMetrics:
        """è·å–å½“å‰æŒ‡æ ‡"""
        return self.collect_metrics()
    
    def get_metrics_summary(self, hours: int = 24) -> Dict[str, Any]:
        """è·å–æŒ‡æ ‡æ‘˜è¦"""
        cutoff = datetime.now() - timedelta(hours=hours)
        recent_metrics = [m for m in self.metrics_history if m.timestamp > cutoff]
        
        if not recent_metrics:
            return {}
        
        return {
            'avg_cpu_percent': sum(m.cpu_percent for m in recent_metrics) / len(recent_metrics),
            'max_cpu_percent': max(m.cpu_percent for m in recent_metrics),
            'avg_memory_mb': sum(m.memory_mb for m in recent_metrics) / len(recent_metrics),
            'max_memory_mb': max(m.memory_mb for m in recent_metrics),
            'avg_cache_hit_rate': sum(m.cache_hit_rate for m in recent_metrics) / len(recent_metrics),
            'total_operations': sum(m.active_operations for m in recent_metrics),
            'total_errors': sum(m.error_count for m in recent_metrics),
            'uptime_hours': (datetime.now() - self.start_time).total_seconds() / 3600
        }

class OptimizedOperation:
    """ä¼˜åŒ–çš„æ“ä½œæ‰§è¡Œå™¨"""
    
    @staticmethod
    def execute_with_caching(
        func: Callable,
        cache_key: str,
        ttl_seconds: int = 3600,
        *args,
        **kwargs
    ) -> Any:
        """å¸¦ç¼“å­˜çš„æ‰§è¡Œ"""
        cache_manager = get_cache_manager()
        
        # å°è¯•ä»ç¼“å­˜è·å–
        result = cache_manager.get(cache_key)
        if result is not None:
            return result
        
        # æ‰§è¡Œå‡½æ•°
        with st.spinner("å¤„ç†ä¸­..."):
            result = func(*args, **kwargs)
        
        # ç¼“å­˜ç»“æœ
        cache_manager.set(cache_key, result, ttl_seconds)
        
        return result
    
    @staticmethod
    def execute_async_with_ui(
        func: Callable,
        operation_name: str,
        *args,
        **kwargs
    ) -> Any:
        """å¸¦UIçš„å¼‚æ­¥æ‰§è¡Œ"""
        return run_async_operation_with_ui(
            func=func,
            operation_name=operation_name,
            operation_description=f"æ‰§è¡Œ {operation_name}",
            *args,
            **kwargs
        )
    
    @staticmethod
    @handle_errors(user_message="æ“ä½œæ‰§è¡Œå¤±è´¥ï¼Œè¯·ç¨åé‡è¯•")
    @track_operation("ä¼˜åŒ–æ“ä½œæ‰§è¡Œ")
    def execute_safe(func: Callable, *args, **kwargs) -> Any:
        """å®‰å…¨æ‰§è¡Œï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰"""
        return func(*args, **kwargs)

# å…¨å±€ç›‘æ§å™¨
_performance_monitor = None

def get_performance_monitor() -> PerformanceMonitor:
    """è·å–å…¨å±€æ€§èƒ½ç›‘æ§å™¨"""
    global _performance_monitor
    if _performance_monitor is None:
        _performance_monitor = PerformanceMonitor()
    return _performance_monitor

# æ€§èƒ½è£…é¥°å™¨
def optimize_performance(
    cache_ttl: Optional[int] = None,
    async_execution: bool = False,
    track_metrics: bool = True
):
    """æ€§èƒ½ä¼˜åŒ–è£…é¥°å™¨"""
    def decorator(func: Callable) -> Callable:
        @wraps(func)
        def wrapper(*args, **kwargs):
            start_time = time.time()
            
            try:
                # ç¼“å­˜æ‰§è¡Œ
                if cache_ttl:
                    cache_manager = get_cache_manager()
                    cache_key = cache_manager._generate_key(func.__name__, args, kwargs)
                    
                    result = cache_manager.get(cache_key)
                    if result is not None:
                        return result
                
                # å¼‚æ­¥æ‰§è¡Œ
                if async_execution:
                    result = run_async_operation_with_ui(
                        func=func,
                        operation_name=func.__name__,
                        operation_description=f"æ‰§è¡Œ {func.__name__}",
                        *args,
                        **kwargs
                    )
                else:
                    result = func(*args, **kwargs)
                
                # ç¼“å­˜ç»“æœ
                if cache_ttl:
                    cache_manager.set(cache_key, result, cache_ttl)
                
                # è®°å½•æ€§èƒ½æŒ‡æ ‡
                if track_metrics:
                    end_time = time.time()
                    execution_time = (end_time - start_time) * 1000  # æ¯«ç§’
                    
                    monitor = get_performance_monitor()
                    metrics = monitor.get_current_metrics()
                    metrics.response_time_ms = execution_time
                    monitor.add_metrics(metrics)
                
                return result
                
            except Exception as e:
                # é”™è¯¯å¤„ç†
                error_handler = get_error_handler()
                error_handler.handle_error(
                    error=e,
                    context=f"optimize_performance({func.__name__})"
                )
                raise
        
        return wrapper
    return decorator

def display_performance_dashboard():
    """æ˜¾ç¤ºæ€§èƒ½ç›‘æ§é¢æ¿"""
    st.subheader("ğŸ“Š æ€§èƒ½ç›‘æ§")
    
    monitor = get_performance_monitor()
    current_metrics = monitor.get_current_metrics()
    summary = monitor.get_metrics_summary(24)
    
    # å®æ—¶æŒ‡æ ‡
    st.write("**å®æ—¶æŒ‡æ ‡**")
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric(
            "CPUä½¿ç”¨ç‡",
            f"{current_metrics.cpu_percent:.1f}%",
            delta=f"{current_metrics.cpu_percent - summary.get('avg_cpu_percent', 0):.1f}%" if summary else None
        )
    
    with col2:
        st.metric(
            "å†…å­˜ä½¿ç”¨",
            f"{current_metrics.memory_mb:.0f}MB",
            delta=f"{current_metrics.memory_mb - summary.get('avg_memory_mb', 0):.0f}MB" if summary else None
        )
    
    with col3:
        st.metric(
            "ç¼“å­˜å‘½ä¸­ç‡",
            f"{current_metrics.cache_hit_rate:.1%}",
            delta=f"{current_metrics.cache_hit_rate - summary.get('avg_cache_hit_rate', 0):.1%}" if summary else None
        )
    
    with col4:
        st.metric(
            "æ´»è·ƒæ“ä½œ",
            current_metrics.active_operations
        )
    
    st.divider()
    
    # 24å°æ—¶æ‘˜è¦
    if summary:
        st.write("**24å°æ—¶æ‘˜è¦**")
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("å¹³å‡CPU", f"{summary['avg_cpu_percent']:.1f}%")
            st.metric("å³°å€¼CPU", f"{summary['max_cpu_percent']:.1f}%")
        
        with col2:
            st.metric("å¹³å‡å†…å­˜", f"{summary['avg_memory_mb']:.0f}MB")
            st.metric("å³°å€¼å†…å­˜", f"{summary['max_memory_mb']:.0f}MB")
        
        with col3:
            st.metric("æ€»æ“ä½œæ•°", summary['total_operations'])
            st.metric("æ€»é”™è¯¯æ•°", summary['total_errors'])
        
        with col4:
            st.metric("è¿è¡Œæ—¶é—´", f"{summary['uptime_hours']:.1f}å°æ—¶")
            st.metric("ç¼“å­˜å‘½ä¸­ç‡", f"{summary['avg_cache_hit_rate']:.1%}")
    
    st.divider()
    
    # æ€§èƒ½å›¾è¡¨
    if len(monitor.metrics_history) > 1:
        st.write("**æ€§èƒ½è¶‹åŠ¿**")
        
        import pandas as pd
        
        # å‡†å¤‡æ•°æ®
        df = pd.DataFrame([
            {
                'time': m.timestamp,
                'CPU%': m.cpu_percent,
                'å†…å­˜MB': m.memory_mb,
                'ç¼“å­˜å‘½ä¸­ç‡': m.cache_hit_rate * 100,
                'æ´»è·ƒæ“ä½œ': m.active_operations
            }
            for m in monitor.metrics_history[-100:]  # æœ€è¿‘100ä¸ªç‚¹
        ])
        
        # æ˜¾ç¤ºå›¾è¡¨
        st.line_chart(df.set_index('time'))
    
    st.divider()
    
    # ä¼˜åŒ–æ“ä½œ
    st.write("**æ€§èƒ½ä¼˜åŒ–**")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.button("ğŸ§¹ æ¸…ç†ç¼“å­˜"):
            cache_manager = get_cache_manager()
            cleaned = cache_manager.cleanup_expired()
            st.success(f"æ¸…ç†äº† {cleaned} ä¸ªè¿‡æœŸç¼“å­˜æ¡ç›®")
    
    with col2:
        if st.button("ğŸ—‘ï¸ å†…å­˜æ¸…ç†"):
            monitor._cleanup_memory()
            st.success("å†…å­˜æ¸…ç†å®Œæˆ")
    
    with col3:
        if st.button("ğŸ“Š é‡ç½®ç»Ÿè®¡"):
            monitor.metrics_history.clear()
            st.success("ç»Ÿè®¡æ•°æ®å·²é‡ç½®")

# å·¥å…·å‡½æ•°
def measure_execution_time(func: Callable) -> Callable:
    """æµ‹é‡æ‰§è¡Œæ—¶é—´è£…é¥°å™¨"""
    @wraps(func)
    def wrapper(*args, **kwargs):
        start_time = time.time()
        result = func(*args, **kwargs)
        end_time = time.time()
        
        execution_time = (end_time - start_time) * 1000
        logger.info(f"Function {func.__name__} executed in {execution_time:.2f}ms")
        
        return result
    
    return wrapper

def get_system_info() -> Dict[str, Any]:
    """è·å–ç³»ç»Ÿä¿¡æ¯"""
    try:
        return {
            'cpu_count': psutil.cpu_count(),
            'memory_total_gb': psutil.virtual_memory().total / (1024**3),
            'python_version': psutil.version_info,
            'boot_time': datetime.fromtimestamp(psutil.boot_time()),
            'load_average': psutil.getloadavg() if hasattr(psutil, 'getloadavg') else None
        }
    except Exception as e:
        logger.error(f"Failed to get system info: {e}")
        return {}

# åˆå§‹åŒ–
def initialize_performance_system():
    """åˆå§‹åŒ–æ€§èƒ½ç³»ç»Ÿ"""
    try:
        # å¯åŠ¨æ€§èƒ½ç›‘æ§
        get_performance_monitor()
        
        # å¯åŠ¨ç¼“å­˜æ¸…ç†
        schedule_cache_cleanup()
        
        logger.info("Performance system initialized")
        
    except Exception as e:
        logger.error(f"Failed to initialize performance system: {e}")

# è‡ªåŠ¨åˆå§‹åŒ–
initialize_performance_system()