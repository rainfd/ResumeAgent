"""Webç•Œé¢ç¼“å­˜ç®¡ç†

ä¼˜åŒ–Streamlitåº”ç”¨çš„æ€§èƒ½é€šè¿‡æ™ºèƒ½ç¼“å­˜ç³»ç»Ÿã€‚
"""

import streamlit as st
import hashlib
import pickle
import json
import time
from typing import Any, Optional, Dict, List, Callable, Union
from datetime import datetime, timedelta
from pathlib import Path
from functools import wraps
from dataclasses import dataclass, field
import os

from ..utils import get_logger

logger = get_logger(__name__)

@dataclass
class CacheEntry:
    """ç¼“å­˜æ¡ç›®"""
    key: str
    value: Any
    created_at: datetime
    expires_at: Optional[datetime] = None
    access_count: int = 0
    last_accessed: datetime = field(default_factory=datetime.now)
    size_bytes: int = 0
    tags: List[str] = field(default_factory=list)
    
    @property
    def is_expired(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦è¿‡æœŸ"""
        if self.expires_at is None:
            return False
        return datetime.now() > self.expires_at
    
    @property
    def age_seconds(self) -> float:
        """è·å–ç¼“å­˜å¹´é¾„ï¼ˆç§’ï¼‰"""
        return (datetime.now() - self.created_at).total_seconds()

class SmartCacheManager:
    """æ™ºèƒ½ç¼“å­˜ç®¡ç†å™¨"""
    
    def __init__(self, max_size_mb: int = 100, default_ttl_seconds: int = 3600):
        self.max_size_bytes = max_size_mb * 1024 * 1024
        self.default_ttl_seconds = default_ttl_seconds
        self.cache: Dict[str, CacheEntry] = {}
        self.stats = {
            'hits': 0,
            'misses': 0,
            'evictions': 0,
            'size_bytes': 0
        }
        
    def _generate_key(self, func_name: str, args: tuple, kwargs: dict) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        # åˆ›å»ºå‚æ•°çš„å“ˆå¸Œ
        param_str = json.dumps({
            'args': str(args),
            'kwargs': sorted(kwargs.items())
        }, sort_keys=True, default=str)
        
        param_hash = hashlib.md5(param_str.encode()).hexdigest()
        return f"{func_name}:{param_hash}"
    
    def _calculate_size(self, value: Any) -> int:
        """è®¡ç®—å¯¹è±¡å¤§å°"""
        try:
            return len(pickle.dumps(value))
        except:
            # å¦‚æœæ— æ³•åºåˆ—åŒ–ï¼Œä½¿ç”¨ä¼°ç®—
            return len(str(value).encode())
    
    def _evict_if_needed(self, required_size: int):
        """å¦‚æœéœ€è¦ï¼Œæ‰§è¡Œç¼“å­˜é©±é€"""
        while (self.stats['size_bytes'] + required_size > self.max_size_bytes and 
               self.cache):
            # LRUé©±é€ï¼šåˆ é™¤æœ€ä¹…æœªè®¿é—®çš„é¡¹
            oldest_key = min(self.cache.keys(), 
                           key=lambda k: self.cache[k].last_accessed)
            
            entry = self.cache.pop(oldest_key)
            self.stats['size_bytes'] -= entry.size_bytes
            self.stats['evictions'] += 1
            
            logger.debug(f"Evicted cache entry: {oldest_key}")
    
    def get(self, key: str) -> Optional[Any]:
        """è·å–ç¼“å­˜å€¼"""
        if key not in self.cache:
            self.stats['misses'] += 1
            return None
        
        entry = self.cache[key]
        
        # æ£€æŸ¥è¿‡æœŸ
        if entry.is_expired:
            self.remove(key)
            self.stats['misses'] += 1
            return None
        
        # æ›´æ–°è®¿é—®ä¿¡æ¯
        entry.access_count += 1
        entry.last_accessed = datetime.now()
        self.stats['hits'] += 1
        
        return entry.value
    
    def set(self, key: str, value: Any, ttl_seconds: Optional[int] = None, 
            tags: Optional[List[str]] = None):
        """è®¾ç½®ç¼“å­˜å€¼"""
        ttl = ttl_seconds or self.default_ttl_seconds
        expires_at = datetime.now() + timedelta(seconds=ttl) if ttl > 0 else None
        
        size_bytes = self._calculate_size(value)
        
        # å¦‚æœéœ€è¦ï¼Œæ‰§è¡Œé©±é€
        self._evict_if_needed(size_bytes)
        
        # å¦‚æœkeyå·²å­˜åœ¨ï¼Œå…ˆåˆ é™¤æ—§çš„
        if key in self.cache:
            self.stats['size_bytes'] -= self.cache[key].size_bytes
        
        # åˆ›å»ºæ–°æ¡ç›®
        entry = CacheEntry(
            key=key,
            value=value,
            created_at=datetime.now(),
            expires_at=expires_at,
            size_bytes=size_bytes,
            tags=tags or []
        )
        
        self.cache[key] = entry
        self.stats['size_bytes'] += size_bytes
        
        logger.debug(f"Cached entry: {key}, size: {size_bytes} bytes")
    
    def remove(self, key: str) -> bool:
        """åˆ é™¤ç¼“å­˜æ¡ç›®"""
        if key in self.cache:
            entry = self.cache.pop(key)
            self.stats['size_bytes'] -= entry.size_bytes
            return True
        return False
    
    def clear(self):
        """æ¸…ç©ºæ‰€æœ‰ç¼“å­˜"""
        self.cache.clear()
        self.stats['size_bytes'] = 0
        logger.info("Cache cleared")
    
    def clear_by_tag(self, tag: str):
        """æ ¹æ®æ ‡ç­¾æ¸…ç©ºç¼“å­˜"""
        keys_to_remove = [
            key for key, entry in self.cache.items()
            if tag in entry.tags
        ]
        
        for key in keys_to_remove:
            self.remove(key)
        
        logger.info(f"Cleared {len(keys_to_remove)} entries with tag: {tag}")
    
    def cleanup_expired(self):
        """æ¸…ç†è¿‡æœŸæ¡ç›®"""
        expired_keys = [
            key for key, entry in self.cache.items()
            if entry.is_expired
        ]
        
        for key in expired_keys:
            self.remove(key)
        
        if expired_keys:
            logger.info(f"Cleaned up {len(expired_keys)} expired entries")
        
        return len(expired_keys)
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        hit_rate = (self.stats['hits'] / 
                   (self.stats['hits'] + self.stats['misses']) 
                   if (self.stats['hits'] + self.stats['misses']) > 0 else 0)
        
        return {
            **self.stats,
            'entries_count': len(self.cache),
            'hit_rate': hit_rate,
            'size_mb': self.stats['size_bytes'] / (1024 * 1024),
            'max_size_mb': self.max_size_bytes / (1024 * 1024)
        }
    
    def get_entries_info(self) -> List[Dict[str, Any]]:
        """è·å–ç¼“å­˜æ¡ç›®ä¿¡æ¯"""
        return [
            {
                'key': entry.key,
                'created_at': entry.created_at,
                'expires_at': entry.expires_at,
                'access_count': entry.access_count,
                'last_accessed': entry.last_accessed,
                'size_bytes': entry.size_bytes,
                'tags': entry.tags,
                'age_seconds': entry.age_seconds,
                'is_expired': entry.is_expired
            }
            for entry in self.cache.values()
        ]

# å…¨å±€ç¼“å­˜ç®¡ç†å™¨
_cache_manager = None

def get_cache_manager() -> SmartCacheManager:
    """è·å–å…¨å±€ç¼“å­˜ç®¡ç†å™¨"""
    global _cache_manager
    if _cache_manager is None:
        _cache_manager = SmartCacheManager()
    return _cache_manager

# Streamlitç¼“å­˜è£…é¥°å™¨
def st_cache(
    ttl_seconds: Optional[int] = None,
    tags: Optional[List[str]] = None,
    show_spinner: bool = True,
    spinner_text: str = "åŠ è½½ä¸­..."
):
    """Streamlitç¼“å­˜è£…é¥°å™¨"""
    def decorator(func: Callable) -> Callable:
        @wraps(func)
        def wrapper(*args, **kwargs):
            cache_manager = get_cache_manager()
            cache_key = cache_manager._generate_key(func.__name__, args, kwargs)
            
            # å°è¯•ä»ç¼“å­˜è·å–
            cached_result = cache_manager.get(cache_key)
            if cached_result is not None:
                return cached_result
            
            # ç¼“å­˜æœªå‘½ä¸­ï¼Œæ‰§è¡Œå‡½æ•°
            if show_spinner:
                with st.spinner(spinner_text):
                    result = func(*args, **kwargs)
            else:
                result = func(*args, **kwargs)
            
            # ç¼“å­˜ç»“æœ
            cache_manager.set(cache_key, result, ttl_seconds, tags)
            
            return result
        
        return wrapper
    return decorator

# ç¼“å­˜ç®¡ç†UIå·¥å…·
def display_cache_stats():
    """æ˜¾ç¤ºç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
    cache_manager = get_cache_manager()
    stats = cache_manager.get_stats()
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("ç¼“å­˜å‘½ä¸­ç‡", f"{stats['hit_rate']:.1%}")
    
    with col2:
        st.metric("ç¼“å­˜æ¡ç›®", stats['entries_count'])
    
    with col3:
        st.metric("ç¼“å­˜å¤§å°", f"{stats['size_mb']:.1f} MB")
    
    with col4:
        st.metric("é©±é€æ¬¡æ•°", stats['evictions'])

def display_cache_management():
    """æ˜¾ç¤ºç¼“å­˜ç®¡ç†ç•Œé¢"""
    st.subheader("ğŸ—„ï¸ ç¼“å­˜ç®¡ç†")
    
    cache_manager = get_cache_manager()
    
    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    display_cache_stats()
    
    st.divider()
    
    # æ“ä½œæŒ‰é’®
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        if st.button("ğŸ§¹ æ¸…ç†è¿‡æœŸ", help="æ¸…ç†æ‰€æœ‰è¿‡æœŸçš„ç¼“å­˜æ¡ç›®"):
            cleaned = cache_manager.cleanup_expired()
            st.success(f"æ¸…ç†äº† {cleaned} ä¸ªè¿‡æœŸæ¡ç›®")
            st.rerun()
    
    with col2:
        if st.button("ğŸ—‘ï¸ æ¸…ç©ºå…¨éƒ¨", help="æ¸…ç©ºæ‰€æœ‰ç¼“å­˜"):
            cache_manager.clear()
            st.success("å·²æ¸…ç©ºæ‰€æœ‰ç¼“å­˜")
            st.rerun()
    
    with col3:
        tag_to_clear = st.selectbox("æŒ‰æ ‡ç­¾æ¸…ç†", 
                                   ["jobs", "resumes", "analyses", "agents", "files", "scraping", "analysis", "greeting"])
        if st.button("ğŸ·ï¸ æ¸…ç†æ ‡ç­¾"):
            cache_manager.clear_by_tag(tag_to_clear)
            st.success(f"å·²æ¸…ç†æ ‡ç­¾ '{tag_to_clear}' çš„ç¼“å­˜")
            st.rerun()
    
    with col4:
        if st.button("ğŸ“Š è¯¦ç»†ä¿¡æ¯", help="æ˜¾ç¤ºç¼“å­˜æ¡ç›®è¯¦ç»†ä¿¡æ¯"):
            st.session_state.show_cache_details = not st.session_state.get('show_cache_details', False)
    
    # æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
    if st.session_state.get('show_cache_details', False):
        st.divider()
        st.subheader("ğŸ“‹ ç¼“å­˜æ¡ç›®è¯¦æƒ…")
        
        entries = cache_manager.get_entries_info()
        if entries:
            import pandas as pd
            df = pd.DataFrame(entries)
            df['created_at'] = df['created_at'].dt.strftime('%Y-%m-%d %H:%M:%S')
            df['last_accessed'] = df['last_accessed'].dt.strftime('%Y-%m-%d %H:%M:%S')
            df['size_kb'] = (df['size_bytes'] / 1024).round(2)
            
            # æ˜¾ç¤ºè¡¨æ ¼
            st.dataframe(
                df[['key', 'created_at', 'last_accessed', 'access_count', 'size_kb', 'tags', 'is_expired']],
                use_container_width=True
            )
        else:
            st.info("æš‚æ— ç¼“å­˜æ¡ç›®")

# è‡ªåŠ¨ç¼“å­˜æ¸…ç†ä»»åŠ¡
def schedule_cache_cleanup():
    """å®‰æ’è‡ªåŠ¨ç¼“å­˜æ¸…ç†ä»»åŠ¡"""
    cache_manager = get_cache_manager()
    
    # æ¯10åˆ†é’Ÿæ¸…ç†ä¸€æ¬¡è¿‡æœŸæ¡ç›®
    last_cleanup = st.session_state.get('last_cache_cleanup', 0)
    now = time.time()
    
    if now - last_cleanup > 600:  # 10åˆ†é’Ÿ
        cleaned = cache_manager.cleanup_expired()
        st.session_state.last_cache_cleanup = now
        
        if cleaned > 0:
            logger.info(f"Auto-cleaned {cleaned} expired cache entries")

# å®ç”¨å·¥å…·å‡½æ•°
def invalidate_cache(tags: Optional[List[str]] = None, keys: Optional[List[str]] = None):
    """ä½¿ç¼“å­˜å¤±æ•ˆ"""
    cache_manager = get_cache_manager()
    
    if tags:
        for tag in tags:
            cache_manager.clear_by_tag(tag)
    
    if keys:
        for key in keys:
            cache_manager.remove(key)

def get_cache_key(func_name: str, *args, **kwargs) -> str:
    """è·å–ç¼“å­˜é”®"""
    cache_manager = get_cache_manager()
    return cache_manager._generate_key(func_name, args, kwargs)